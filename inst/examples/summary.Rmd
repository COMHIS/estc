---
title: "Preprocessing Summary"
author: "Leo Lahti"
date: "16/05/2015"
output: markdown_document
---

# Summary of the preprocessed ESTC data

## Field conversions

This document links to files that summarize the conversions from raw data to the final preprocessed version (accepted, discarded, conversions). Only some of the key tables are explicitly linked below. The complete list of those summary tables is available [here](output.tables/).



```{r summaryinit, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
library(stringr)
library(bibliographica)
library(estc)
df <- read.csv(file = "estc.csv", sep = "|")

# Order the levels where necessary
df$gatherings <- order_gatherings(df$gatherings)
df.preprocessed <- df
ntop <- 20
```





## Annotated documents

Fraction of documents with entries for each annotation field (final preprocessed data).

```{r summaryannotations, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=8, fig.height=7}
library(dplyr)
library(ggplot2)
missing <- 100*apply(df, 2, function (x) {mean(is.na(x))})
df3 <- data.frame(list(missing = missing, field = names(missing)))
df3$field <- factor(df3$field, levels = df3$field[rev(order(df3$missing))])
theme_set(theme_bw(15))
p <- ggplot(df3, aes(x = field, y = 100 - missing))
p <- p + geom_bar(stat = "identity")
p <- p + coord_flip()
p <- p + ylab("")
p <- p + xlab("")
p <- p + ggtitle("Documents with data (%)")
print(p)
```

Number of documents with NA entries (number and percentage) and number of unique entries for each field:

```{r sumtab, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
tab <- cbind(docs = colSums(!is.na(df)),
             percentage = colMeans(!is.na(df)),
      unique = apply(df, 2, function (x) {length(unique(x))}))
tab <- tab[order(tab[, "docs"]), ]
kable(tab)
```


## Topics

```{r summarytopics, echo=FALSE, message=FALSE, warning=FALSE}
# List all topics
spl <- strsplit(na.omit(as.character(df$topic)), ";")

# Documents per topic
tab <- sort(table(unlist(spl)))
tab <- tab[!names(tab) == "NA"]
tab <- rev(sort(tab)) 
```


Top-`r ntop` topics and number of documents for each. In total, there are `r length(unique(df$topic))` unique topics and `r sum(!is.na(df$topic))` documents assigned to one or more topics (`r round(100*mean(!is.na(df$topic)))`).

```{r summarytopics22, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=8}
p <- top_plot(df, "topic", ntop)
p <- p + ggtitle(paste("Most common topics"))
p <- p + ylab("Documents")
print(p)
```


## Authors

[Discarded author names](output.tables/author_name_discarded.csv)

[Discarded author first names](output.tables/author_name_discarded_first.csv)

[Discarded author last names](output.tables/author_name_discarded_last.csv)


Top-`r ntop` uniquely identified authors and number of documents for each (duplicate docs not checked yet). In total, there are `r length(unique(df$author_unique))` unique authors and `r sum(!is.na(df$author_unique))` documents with unambiguous author information (`r round(100*mean(!is.na(df$author_name)))`%).


```{r summaryauthors, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
p <- top_plot(df, "author_unique", ntop)
p <- p + ggtitle(paste("Top authors"))
p <- p + ylab("Documents")
print(p)
```



### Gender

[Author genders](output.tables/author_gender_accepted.csv)

[Male authors](output.tables/gender_male.csv)

[Female authors](output.tables/gender_male.csv)

[Names with missing gender](output.tables/gender_unknown.csv)


Author gender distribution in the complete data:

```{r summarygender0, echo=FALSE, message=FALSE, warning=FALSE}
kable(df %>% group_by(author_gender) %>% summarize(docs = n(), fraction = round(100*n()/nrow(df), 2)))
```

Author gender distribution over time. Note that the name-gender mappings change over time. This has not been taken into account yet.


```{r summarygendertime, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=5}
tab <- table(df$author_gender)
dfd <- df %>% group_by(publication_decade) %>% summarize(n.male = sum(author_gender == "male", na.rm = T), n.female = sum(author_gender == "female", na.rm = T), n.total = n()) %>% mutate(p.male = 100*n.male/n.total, p.female = 100*n.female/n.total) %>% filter(n.total > 25) 
dfy <- df %>% group_by(publication_year) %>% summarize(n.male = sum(author_gender == "male", na.rm = T), n.female = sum(author_gender == "female", na.rm = T), n.total = n()) %>% mutate(p.male = 100*n.male/n.total, p.female = 100*n.female/n.total) %>% filter(n.total > 25) 
library(sorvi)
p <- regression_plot(p.female ~ publication_decade, dfd, main = "Female authors proportion")
p <- p + ylab("Female authors (%)")
print(p)
```



### Ambiguous authors

Authors with ambiguous living year information - can we spot here
cases where these are clearly known identical or distinct authors?
Should also add living year information from supporting sources later.

[Authors with ambiguous life years](output.tables/author_life_ambiguous.csv)

[Authors with discarded life years](output.tables/author_life_discarded.csv)

[Authors with missing life years](output.tables/author_birth_unknown.csv)


### Life span of uniquely identified top authors

Ordered by productivity (number of documents))

```{r, summaryauthorslife, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
a <- rev(rev(sort(table(df$author_unique)))[1:ntop])
dfa <- df[, c("author_unique", "author_birth", "author_death")]
dfa <- filter(dfa, !is.na(author_unique) & (author_unique %in% names(a)))
dfa <- dfa[!duplicated(dfa), ]
dfa <- dfa[match(names(a), dfa$author_unique),]
dfa <- arrange(dfa, author_birth)
# Order authors by birth year
dfa$author_unique <- factor(dfa$author_unique, levels = dfa$author_unique)
dfa$index <- 1:nrow(dfa)

p <- ggplot(dfa)
p <- p + geom_segment(aes(y = author_unique, yend = author_unique, x = author_birth, xend = author_death), size = 2) 
p <- p + theme(axis.text.y = element_text(size = 9))
p <- p + xlab("Author life span (year)") + ylab("")
print(p)
```

### Publication timeline for top-10 authors

Title count

```{r summaryTop10authorstimeline, fig.height=30, fig.width=10, echo=FALSE}
top10 <- names(sort(table(df$author_unique), decreasing = TRUE))[1:10]
dfs <- filter(df, author_unique %in% top10)
dfs <- group_by(dfs, author_unique, publication_year) %>% summarize(ndoc = n())
p <- ggplot(dfs, aes(x = publication_year, y = ndoc)) 
p <- p + geom_bar(stat = "identity") 
p <- p + facet_grid(author_unique ~ .)
p <- p + ggtitle("Number of documents per year for top-10 titlecount authors")
print(p)
#publications.annual <- tapply(df$unity, list(df$publication_year, df$publication_place), sum)
#publications.annual[is.na(publications.annual)] <- 0 # Set NAs to 0
#dfm.annual <- melt(publications.annual) 
#names(dfm.annual) <- c("Time", "Place", "Documents")
#?Daniel Defoe
#?Julius Caesar
#?Buchanan
```


Paper consumption

```{r summaryTop10authorstimelinepaper, fig.height=30, fig.width=10, echo=FALSE}
# Calculate paper consumption for authors
df2 <- df %>%
    group_by(author_unique) %>%
    summarize(paper.consumption.km2 = sum(paper.consumption.km2, na.rm = TRUE), n = n()) 
# Pick top-10 paper authors
top10 <- na.omit(as.character(df2[order(df2$paper.consumption.km2, decreasing = TRUE), ]$author_unique))[1:10]
dfs <- filter(df, author_unique %in% top10)
dfs <- group_by(dfs, author_unique, publication_year) %>%
    summarize(paper.consumption.km2 = sum(paper.consumption.km2, na.rm = TRUE), n = n()) 
p <- ggplot(dfs, aes(x = publication_year, y = paper.consumption.km2)) 
p <- p + geom_bar(stat = "identity") 
p <- p + facet_grid(author_unique ~ .)
p <- p + ggtitle("Paper comsumption per year for top-10 paper authors")
print(p)
```




## Publication 

### Publication places

Top-`r ntop` publication places are shown together with the number of documents. This info is available for `r sum(!is.na(df$publication_place))` documents (`r round(100*mean(!is.na(df$publication_place)))`%). There are `r length(unique(str_trim(unlist(strsplit(as.character(df$publication_place), ";")))))` unique publication places. Overall `r round(100*mean(!is.na(df$latitude) & !is.na(df$longitude)), 1)`% of the places could be matched to geographic coordinates (from the [Geonames](http://download.geonames.org/export/dump/) database).

[Publication countries](output.tables/publication_country_accepted.csv)

[Publication country missing](output.tables/publication_country_discarded.csv)

[Discarded publication places](output.tables/publication_place_discarded.csv)

[Publication place conversions](output.tables/publication_place_conversions_nontrivial.csv)

[Places missing geocoordinate information](output.tables/absentgeocoordinates.csv)


```{r summaryplace, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=9}
p <- top_plot(df, "publication_place", ntop)
p <- p + ggtitle(paste("Top publication places"))
p <- p + scale_y_log10()
p <- p + ylab("Documents")
print(p)
```


```{r summaryplace3, echo=FALSE, results='asis'}
kable(data.frame(n = rev(sort(table(df$publication_country)))), caption = "Publication country counts")
```


### Publishers

```{r summarypublisher, echo=FALSE, message=FALSE, warning=FALSE}
tab <- rev(sort(table(str_trim(unlist(df$publisher)))))
```

The `r ntop` most common publishers are shown with the number of documents. Publisher information is available for `r sum(!is.na(df$publisher))` documents (`r round(100*mean(!is.na(df$publisher)))`%). There are `r length(tab)` unique publisher names (some may be synonymes, though).


```{r summarypublisher2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=12, fig.height=9}
p <- top_plot(df, "publisher", ntop)
p <- p + ggtitle(paste("Top publishers"))
p <- p + scale_y_log10()
p <- p + ylab("Documents")
print(p)
```


[Publishers accepted](output.tables/publisher_accepted.csv)

[Publishers discarded](output.tables/publisher_discarded.csv)


### Publication timeline for top-10 publishers

Title count

```{r summaryTop10publisherstimeline, fig.height=30, fig.width=10, echo=FALSE, warning=FALSE}
top10 <- na.omit(names(sort(table(df$publisher), decreasing = TRUE)))[1:10]
dfs <- filter(df, publisher %in% top10)
dfs <- group_by(dfs, publisher, publication_year) %>% summarize(ndoc = n())
p <- ggplot(dfs, aes(x = publication_year, y = ndoc)) 
p <- p + geom_bar(stat = "identity") 
p <- p + facet_grid(publisher ~ .)
p <- p + ggtitle("Number of documents per year for top-10 titlecount publishers")
print(p)
```


Paper consumption

```{r summaryTop10publisherstimelinepaper, fig.height=30, fig.width=10, echo=FALSE}
# Calculate paper consumption for publishers
df2 <- df %>%
    group_by(publisher) %>%
    summarize(paper.consumption.km2 = sum(paper.consumption.km2, na.rm = TRUE), n = n()) 
# Pick top-10 paper publishers
o <- order(df2$paper.consumption.km2, decreasing = TRUE)
top10 <- na.omit(df2$publisher[o])[1:10]
dfs <- filter(df, publisher %in% top10)
dfs <- group_by(dfs, publisher, publication_year) %>%
    summarize(paper.consumption.km2 = sum(paper.consumption.km2, na.rm = TRUE), n = n()) 
p <- ggplot(dfs, aes(x = publication_year, y = paper.consumption.km2)) 
p <- p + geom_bar(stat = "identity") 
p <- p + facet_grid(publisher ~ .)
p <- p + ggtitle("Paper consumption per year for top-10 paper publishers")
print(p)
```





### Publication year

Publication year is available for `r sum(!is.na(df$publication_year))` documents (`r round(100*mean(!is.na(df$publication_year)))`%). The publication years span `r paste(range(na.omit(df$publication_year)), collapse = "-")`

```{r summarypublicationyear, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
p <- ggplot(df, aes(x = publication_year)) 
p <- p + geom_histogram(binwidth = 5)
p <- p + ggtitle("Publication year")
print(p)
```

Zooming in 1470-1799

```{r summarypublicationyear2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
p <- ggplot(filter(df, publication_year >=1470 & publication_year < 1800), aes(x = publication_year)) 
p <- p + geom_histogram(binwidth = 5)
p <- p + ggtitle("Publication year")
print(p)
```




[Publication year conversions](output.tables/publication_year_conversion_table.csv)

[Publication year discarded](output.tables/publication_year_failed.csv)


### Titles

Top-`r ntop` titles are shown together with the number of documents. This info is available for `r sum(!is.na(df$title))` documents (`r round(100*mean(!is.na(df$title)))`%). There are `r length(unique(df$title))` unique titles.

[Publication titles](output.tables/title_accepted.csv)

[Publication titles discarded](output.tables/title_discarded.csv)

[Title harmonization table](output.tables/title_conversions_nontrivial.csv)

```{r summarytitle, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10}
tab <- rev(sort(table(df$title)))
p <- top_plot(df, "title", ntop)
p <- p + ggtitle(paste("Top titles"))
p <- p + scale_y_log10()
p <- p + ylab("Documents")
print(p)
```


## Language

The `r length(unique(df$language))` unique languages are shown together with the number of documents. This info is available for `r sum(!is.na(df$language))` documents (`r round(100*mean(!is.na(df$language)))`%). 

```{r summarylang, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7, fig.height=6}
p <- top_plot(df, "language", ntop)
p <- p + ggtitle(paste("Top languages"))
p <- p + scale_y_log10()
p <- p + ylab("Documents")
p <- p + guides(color = "none")
print(p)
```



## Page counts

[Page conversions from raw data to final page count estimates](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/page_conversion_table_brief.csv)

[Page conversions from raw data to final page count estimates with volume info](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/page_conversion_table_full.csv)

[Discarded page info](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/documentpages-discarded.csv)



## Document size comparisons

[Discarded dimension info](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/dimensions_discarded.csv)

[Dimension conversion table](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/dimension_conversion_table.csv)


Document size (area) info in area is available for `r sum(!is.na(df$area))` documents (`r round(100*mean(!is.na(df$area)))`%). Estimates of document size (area) info in gatherings system are available for `r sum(!is.na(df$gatherings))` documents (`r round(100*mean(!is.na(df$gatherings)))`%). 

```{r summarysize, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=5}
df <- df.preprocessed
p <- ggplot(df, aes(x = gatherings)) 
p <- p + geom_bar()
n <- nchar(max(na.omit(table(df$gatherings))))
p <- p + scale_y_log10(breaks=10^(0:n))
p <- p + ggtitle("Document size (gatherings)")
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Document count")
p <- p + coord_flip()
print(p)
```

Compare gatherings and area sizes as a quality check. This includes all data; the area has been estimated from the gatherings when dimension information was not available.

```{r summarysizecomp, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
library(reshape2)
dfs <- df.preprocessed %>% filter(!is.na(area) & !is.na(gatherings))
dfs <- dfs[, c("gatherings", "area")]
dfm <- melt(table(dfs))
names(dfm) <- c("gatherings", "area", "documents")
dfm$gatherings <- factor(dfm$gatherings, levels = levels(df$gatherings))
p <- ggplot(dfm, aes(x = gatherings, y = area)) 
p <- p + scale_y_continuous(trans = "log2")
p <- p + geom_point(aes(size = documents))
p <- p + scale_size(trans="log10")
p <- p + ggtitle("Document size distribution: gatherings vs. area")
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Size (area)")
p <- p + coord_flip()
print(p)
```

Document dimension histogram (surface area). Few document sizes dominate publishing.

```{r summary-surfacearea, fig.height=8, fig.width=10, echo=FALSE, warning=FALSE, message=FALSE}
p <- ggplot(df, aes(x = area))
#bw <- diff(range(na.omit(df$area)))/30
p <- p + geom_histogram() 
p <- p + xlab("Document surface area (log10)")
p <- p + ggtitle("Document dimension (surface area)")
p <- p + scale_x_log10()
print(p)
```



Compare gatherings and page counts. Page count information is estimated for `r sum(!is.na(df$pagecount.orig)) - sum(!is.na(df$pagecount))` documents and updated (changed) for `r sum(!df$pagecount.orig == df$pagecount, na.rm = T)` documents. 

```{r summarypagecomp, echo=FALSE, message=FALSE, warning=FALSE, fig.width=15, fig.height=7}
dfs <- select(df, pagecount, gatherings) 
dfs$pagecount <- as.numeric(gsub(" pages", "", dfs$pagecount))
dfs <- dfs %>% filter(!is.na(pagecount) & !is.na(gatherings))
dfg <- group_by(dfs, pagecount, gatherings) %>% tally()
names(dfg) <- c("pages", "gatherings", "documents")
dfg$gatherings <- factor(dfg$gatherings, levels = levels(df$gatherings))
ylims <- range(dfg$pages)
p <- ggplot(dfg, aes(x = gatherings, y = pages)) 
#p <- p + scale_y_continuous(trans = "log10")
n <- nchar(max(na.omit(table(dfg$pages))))
ylim <- ylim(ylims)
p <- p + scale_y_log10(breaks=10^(0:n))
p <- p + geom_point(aes(size = documents))
p <- p + scale_size(trans="log10")
p <- p + ggtitle(paste("gatherings vs. estimated and original pages (n=", sum(dfg$documents), ")", sep = ""))
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Pages (original and estimated)")
p <- p + coord_flip()
p1 <- p

dfs <- df
dfs$pagecount.orig <- as.numeric(as.character(gsub(" pages", "", dfs$pagecount.orig)))
p <- ggplot(dfs, aes(x = pagecount.orig, y = pagecount)) 
p <- p + geom_point()
p <- p + scale_x_log10()
p <- p + scale_y_log10()
p <- p + ggtitle("Original vs. Estimated pages (when original is not NA)")
p <- p + xlab("Original pages")
p <- p + ylab("Estimated pages")
p2 <- p

library(gridExtra)
grid.arrange(p1, p2, nrow = 1)
```

Compare original gatherings and original heights where both are available. The point size indicates the number of documents with the corresponding combination. The red dots indicate the estimated height that is used when only gathering information is available. It seems that in most documents, the given height is smaller than the correponding estimate.

```{r summarysizevalidation, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
# Compare given dimensions to gatherings
# (not so much data with width so skip that)
df2 <- filter(df, !is.na(height) | !is.na(width))
df2 <- df2[!is.na(as.character(df2$gatherings)),]
df3 <- filter(df2, !is.na(height))
ss <- sheet_sizes()
df3$gathering.height.estimate <- ss[match(df3$gatherings, ss$gatherings),"height"]
df4 <- df3 %>% group_by(gatherings, height) %>% tally()
p <- ggplot(df4, aes(y = gatherings, x = height))
p <- p + geom_point(aes(size = n))
p <- p + geom_point(data = unique(df3), aes(y = gatherings, x = gathering.height.estimate), color = "red")
p <- p + ylab("Gatherings (original)") + xlab("Height (original)") 
p <- p + ggtitle("Height comparison")
print(p)
```

## Average page counts 

Multi-volume documents average page counts are given per volume.

```{r summarypagecountsmulti, echo=FALSE, message=FALSE, warning=FALSE}
output.folder <- "output.tables/"
mean.pagecounts <- read.csv(paste(output.folder, "estimated_page_counts.csv", sep = ""))
mean.pagecounts$doc.dimension <- order_gatherings(mean.pagecounts$doc.dimension)

kable(mean.pagecounts, caption = "Average page counts")
```


```{r summarypagecountsmulti2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=15, fig.height=6}
library(reshape2)
p <- ggplot(melt(mean.pagecounts[, c("median.pages.multivol", "median.pages.singlevol", "median.pages.issue", "doc.dimension")]), aes(fill = variable, y = value, x = doc.dimension)) 
p <- p + geom_bar(stat = "identity", position = "dodge")
p <- p + ylab("Pages")
p <- p + xlab("")
p <- p + coord_flip()
p <- p + ggtitle("Median page counts")
p1 <- p

p <- ggplot(melt(mean.pagecounts[, c("mean.pages.multivol", "mean.pages.singlevol", "mean.pages.issue", "doc.dimension")]), aes(fill = variable, y = value, x = doc.dimension)) 
p <- p + geom_bar(stat = "identity", position = "dodge")
p <- p + ylab("Pages")
p <- p + xlab("")
p <- p + coord_flip()
p <- p + ggtitle("Mean page counts")
p2 <- p

library(gridExtra)
grid.arrange(p1, p2, nrow = 1)
```


## Average document dimensions 

```{r summaryavedimstime, echo=FALSE, message=FALSE, warning=FALSE, fig.width=12, fig.height=7}
df2 <- filter(df, !is.na(gatherings) & (!is.na(height) | !is.na(width))) %>% group_by(gatherings, publication_decade) %>% 
  summarize(mean.height = mean(height, na.rm = T),
    	    mean.width = mean(width, na.rm = T), n = n())

p <- ggplot(df2, aes(x = publication_decade, y = mean.height, group = gatherings, color = gatherings))
p <- p + geom_point(aes(size = n))
p <- p + geom_line(method = "loess")
p <- p + ggtitle("Height")
print(p)
```


```{r summaryavedims, echo=FALSE, message=FALSE, warning=FALSE}
df2 <- filter(df, !is.na(gatherings) & (!is.na(height) | !is.na(width))) %>% group_by(gatherings) %>% 
  summarize(mean.height = mean(height, na.rm = T),
	    median.height = mean(height, na.rm = T),
    	    mean.width = mean(width, na.rm = T), 
	    median.width = mean(width, na.rm = T), 
	    n = n()) %>%
  filter(n > 10 & !is.na(as.character(gatherings)))
mean.dimensions <- as.data.frame(df2)
kable(mean.dimensions, caption = "Average document dimensions")
```

## Histograms of all entries for numeric variables

```{r summary-histograms, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height=6}
numeric.fields <- c("volnumber", "volcount", "pagecount", "width", "height", "area", "author_birth", "author_death", "publication_year", "publication_decade", "latitude", "longitude", "paper.consumption.km2")
for (field in numeric.fields) {
  df$fieldtoplot <- df[[field]]
  p <- ggplot(df, aes(x = fieldtoplot))
  p <- p + geom_histogram()
  p <- p + scale_x_log10()
  p <- p + ggtitle(paste(field, "histogram"))
  p <- p + ylab("Documents")
  p <- p + xlab(paste(field, "(log10)"))  
  print(p)
}
```

## Histograms of the top entries for factor variables

```{r summary-bars, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height=8}
factor.fields <- c("title", "topic", "author_name", "gatherings", "obl", "publisher", "publisher.printedfor", "publication_place", "publication_country", "author_unique", "author_gender")
for (field in factor.fields) {
  df$fieldtoplot <- df[[field]]
  p <- top_plot(df, "fieldtoplot", min(length(unique(df[[field]])), ntop))
  p <- p + ggtitle(paste("Top ", field))
  p <- p + scale_y_log10()
  p <- p + ylab("Documents (log10)")
  print(p)
}
```














<!--
### Testing rCharts example - perhaps only in HTML with knit2html
```{r, echo=FALSE,results='asis',comment=NA}
library(rCharts)
hair_eye_male <- subset(as.data.frame(HairEyeColor), Sex == "Male")
n1 <- nPlot(Freq ~ Hair, group = "Eye", data = hair_eye_male, type = "multiBarChart")
n1$show('iframesrc',cdn=TRUE)
```
-->

