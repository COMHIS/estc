---
title: "Preprocessing Summary"
author: "Leo Lahti"
date: "04/03/2016"
output: markdown_document
---

# Summary

## Field conversions

This documents the conversions from raw data to the final preprocessed version (accepted, discarded, conversions). Only some of the key tables are explicitly linked below. The complete list of all summary tables is [here](output.tables/).


```{r summaryinit, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
library(bibliographica)
library(knitr)
library(magrittr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(sorvi)
library(reshape2)
library(stringr)

# Set global parameters
ntop <- 20

# Read the preprocessed data
df <- readRDS("estc.Rds")
#df <- read.csv(file = "estc.csv", sep = "|")
# Order the levels where necessary
#df$gatherings <- order_gatherings(df$gatherings)

df <- filter(df, publication_year >= 1460 & publication_year <= 1830)
```


## Annotated documents

Fraction of documents with entries for each annotation field (final preprocessed data).

```{r summaryannotations, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE, fig.width=8, fig.height=11}
availability <- field_availability(df)
print(availability$plot)
```

Documents with data (number and percentage) and number of unique entries for each field:

```{r sumtab, echo=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
tab <- availability$table %<>% arrange(n)
kable(tab[, c(1, 3, 2, 4, 5)])
```



## Authors

[Accepted author names](output.tables/author_accepted.csv)

[Discarded author names](output.tables/author_discarded.csv)

[Author name conversions](output.tables/author_conversion_nontrivial.csv)

Top-`r ntop` uniquely identified authors and number of documents for each (duplicate docs not checked yet). In total, there are `r length(unique(df$author))` unique authors and `r sum(!is.na(df$author))` documents with unambiguous author information (`r round(100*mean(!is.na(df$author_name)))`%).

```{r summaryauthors, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=10, out.width='430px', fig.show='hold'}
p <- NULL
p <- top_plot(df, "author", ntop) +
     		  ggtitle(paste("Top authors")) +
		  ylab("Documents")
print(p)

p <- top_plot(df[is.na(df$author), ] %>% select(author_name), "author_name", ntop) + ggtitle("Top discarded authors")
print(p)
```


Title count versus paper consumption (all authors):

```{r authortitlespapers, fig.height=8, fig.width=16, echo=FALSE, warning=FALSE}
res1 <- compare_title_paper(df, "author", plot.mode = "text")
res2 <- compare_title_paper(df, "author", plot.mode = "point")
grid.arrange(res2$plot, res1$plot, nrow = 1)
#kable(res1$table)
```


### Ambiguous authors

Authors with ambiguous living year information - can we spot here
cases where these are clearly known identical or distinct authors?
Should also add living year information from supporting sources later.

[Authors with ambiguous life years](output.tables/author_life_ambiguous.csv)

[Authors with missing life years](output.tables/authors_missing_lifeyears.csv)


### Publication timeline for top authors

Title count

```{r summaryTop10authorstimeline, fig.height=10, fig.width=20, echo=FALSE}
theme_set(theme_bw(20))
top.authors <- names(top(df, field = "author", n = 3))
dfs <- df %>% filter(author %in% top.authors) %>%
       	 filter(publication_decade > 1450) %>%
     	 group_by(author, publication_decade) %>%
     	 tally() %>%
     	 arrange(publication_decade)
p <- ggplot(dfs, aes(x = publication_decade, y = n, fill = author)) +
       geom_bar(stat = "identity", position = "stack", color = "black") +
       xlab("Publication Decade") +
       ylab("Title Count") +
       scale_fill_grey() +
       guides(fill = guide_legend("Author")) +
       ggtitle("Title count timeline for the top authors")
print(p)
```


## Publication 

### Publication places

[Publication countries](output.tables/country_accepted.csv)

[Publication country not identified](output.tables/country_discarded.csv)

[Discarded publication places](output.tables/publication_place_discarded.csv)

[Publication place conversions](output.tables/publication_place_conversion_nontrivial.csv)

[Places missing geocoordinate information](output.tables/absentgeocoordinates.csv)


Top-`r ntop` publication places are shown together with the number of documents. This info is available for `r sum(!is.na(df$publication_place))` documents (`r round(100*mean(!is.na(df$publication_place)))`%). There are `r length(unique(str_trim(unlist(strsplit(as.character(df$publication_place), ";")))))` unique publication places. Overall `r round(100*mean(!is.na(df$latitude) & !is.na(df$longitude)), 1)`% of the places could be matched to geographic coordinates (from the [Geonames](http://download.geonames.org/export/dump/) database).


```{r summaryplace, echo=FALSE, message=FALSE, warning=FALSE, fig.width=5, fig.height=4, fig.show='hold', out.width='430px'}
p <- top_plot(df, "publication_place", ntop)
p <- p + ggtitle(paste("Top publication places"))
p <- p + scale_y_log10()
p <- p + ylab("Title count")
print(p)

p <- top_plot(df, "country", ntop)
p <- p + ggtitle(paste("Top publication countries"))
p <- p + scale_y_log10()
p <- p + ylab("Title count")
print(p)
```


```{r summaryplace3, echo=FALSE, results='asis'}
pubc <- top(df, "country", output = "data.frame")
kable(head(pubc), caption = "Top publication country counts")
```


### Publishers

[Publishers accepted](output.tables/publisher_accepted.csv)

[Publishers discarded](output.tables/publisher_discarded.csv)


```{r summarypublisher, echo=FALSE, message=FALSE, warning=FALSE}
tab <- top(df, "publisher", output = "data.frame")
```

The `r ntop` most common publishers are shown with the number of documents. Publisher information is available for `r sum(!is.na(df$publisher))` documents (`r round(100*mean(!is.na(df$publisher)))`%). There are `r nrow(tab)` unique publisher names (some may be synonymes, though).


```{r summarypublisher2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=12, fig.height=9}
p <- top_plot(df, "publisher", ntop)
p <- p + ggtitle(paste("Top publishers"))
p <- p + scale_y_log10()
p <- p + ylab("Documents")
print(p)
```

### Publication timeline for top publishers

```{r summaryTop10pubtimeline, fig.height=10, fig.width=20, echo=FALSE}
theme_set(theme_bw(20))
tops <- names(top(df, field = "publisher", n = 5))
field <- "publisher"
dfs <- df
dfs$field <- dfs[[field]]
dfs <- dfs %>% filter(field %in% tops) %>%
       	 filter(publication_decade > 1450) %>%
     	 group_by(field, publication_decade) %>%
     	 tally() %>%
     	 arrange(publication_decade)
p <- ggplot(dfs, aes(x = publication_decade, y = n, fill = field)) +
       geom_bar(stat = "identity", position = "stack", color = "black") +
       xlab("Publication Decade") +
       ylab("Title Count") +
       scale_fill_grey() +
       guides(fill = guide_legend("field")) +
       ggtitle("Title count timeline for the top publishers")
print(p)
```




Title count versus paper consumption (top publishers):

```{r publishertitlespapers, fig.height=5, fig.width=10, echo=FALSE, warning=FALSE}
res <- compare_title_paper(df, "publisher", selected = tops)
print(res$plot)  
kable(res$table)
```

### Publication year

[Publication year conversions](output.tables/publication_year_conversion_nontrivial.csv)

[Publication year discarded](output.tables/publication_year_discarded.csv)


Publication year is available for `r sum(!is.na(df$publication_year))` documents (`r round(100*mean(!is.na(df$publication_year)))`%). The publication years span `r paste(range(na.omit(df$publication_year)), collapse = "-")`

```{r summarypublicationyear, echo=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=6}
# Title count per decade
df2 <- df %>% group_by(publication_decade) %>% filter(publication_decade < 2010) 
p <- ggplot(df2, aes(publication_decade)) +
     geom_bar() + scale_y_log10() +
     ggtitle("Title count timeline")
print(p)
```


### Titles

Top-`r ntop` titles are shown together with the number of documents. This info is available for `r sum(!is.na(df$title))` documents (`r round(100*mean(!is.na(df$title)))`%). There are `r length(unique(df$title))` unique titles.

```{r summarytitle, echo=FALSE, message=FALSE, warning=FALSE, fig.width=16, fig.height=10}
#[Publication titles](output.tables/title_accepted.csv)
#[Publication titles discarded](output.tables/title_discarded.csv)
#[Title harmonization table](output.tables/title_conversion_nontrivial.csv)
p <- top_plot(df, "title", ntop = ntop) +
  ggtitle(paste("Top titles")) +
  scale_y_log10() +
  ylab("Documents")
print(p)
```


## Language

Title count for the `r ncol(df %>% select(starts_with("language.")))-1` unique languages. Some documents have more than one language listed.

[Unrecognized language entries](output.tables/language_unidentified.csv)  

```{r summarylang, echo=FALSE, message=FALSE, warning=FALSE, fig.width=7, fig.height=6}
dfs <- select(df, starts_with("language.")) %>% gather() %>% filter(value) %>% group_by(key) #%>% tally() %>% arrange(n)
dfs$key <- gsub("language\\.", "", dfs$key)

p <- top_plot(dfs, "key", nrow(dfs)) +
  ggtitle(paste("Languages")) +
  scale_y_log10() +
  ylab("Documents") +
  guides(color = "none")
print(p)
```

## Page counts

[Page conversions from raw data to final page count estimates](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/pagecount_conversion_nontrivial.csv)

[Discarded pagecount info](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/pagecount_discarded.csv)



## Document size comparisons

[Dimension conversion table](https://raw.githubusercontent.com/rOpenGov/estc/master/inst/examples/output.tables/conversions_physical_dimension.csv)

Document size (area) info in area is available for `r sum(!is.na(df$area))` documents (`r round(100*mean(!is.na(df$area)))`%). Estimates of document size (area) info in gatherings system are available for `r sum(!is.na(df$gatherings))` documents (`r round(100*mean(!is.na(df$gatherings)))`%). 

```{r summarysize, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=5}
p <- ggplot(df, aes(x = gatherings)) 
p <- p + geom_bar()
n <- nchar(max(na.omit(table(df$gatherings))))
p <- p + scale_y_log10(breaks=10^(0:n))
p <- p + ggtitle("Document size (gatherings)")
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Title count")
p <- p + coord_flip()
print(p)
```

Compare gatherings and area sizes as a quality check. This includes all data; the area has been estimated from the gatherings when dimension information was not available.

```{r summarysizecomp, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
dfs <- df %>% filter(!is.na(area) & !is.na(gatherings))
dfs <- dfs[, c("gatherings", "area")]
dfm <- melt(table(dfs)) # TODO switch to gather here
names(dfm) <- c("gatherings", "area", "documents")
dfm$gatherings <- factor(dfm$gatherings, levels = levels(df$gatherings))
p <- ggplot(dfm, aes(x = gatherings, y = area)) 
p <- p + scale_y_continuous(trans = "log2")
p <- p + geom_point(aes(size = documents))
p <- p + scale_size(trans="log10")
p <- p + ggtitle("Document size distribution: gatherings vs. area")
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Size (area)")
p <- p + coord_flip()
print(p)
```


Compare gatherings and page counts. Page count information is estimated for `r sum(!is.na(df$pagecount)) - sum(!is.na(df$pagecount))` documents and updated (changed) for `r sum(!df$pagecount.orig == df$pagecount, na.rm = T)` documents. 

```{r summarypagecomp, echo=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=7}
dfs <- select(df, pagecount, gatherings) 
dfs$pagecount <- as.numeric(gsub(" pages", "", dfs$pagecount))
dfs <- dfs %>% filter(!is.na(pagecount) & !is.na(gatherings))
dfg <- group_by(dfs, pagecount, gatherings) %>% tally()
names(dfg) <- c("pages", "gatherings", "documents")
dfg$gatherings <- factor(dfg$gatherings, levels = levels(df$gatherings))
ylims <- range(dfg$pages)
p <- ggplot(dfg, aes(x = gatherings, y = pages)) 
#p <- p + scale_y_continuous(trans = "log10")
n <- nchar(max(na.omit(table(dfg$pages))))
ylim <- ylim(ylims)
p <- p + scale_y_log10(breaks=10^(0:n))
p <- p + geom_point(aes(size = documents))
p <- p + scale_size(trans="log10")
p <- p + ggtitle(paste("gatherings vs. estimated and original pages (n=", sum(dfg$documents), ")", sep = ""))
p <- p + xlab("Size (gatherings)")
p <- p + ylab("Pages (original and estimated)")
p <- p + coord_flip()
print(p)
```

Compare original gatherings and original heights where both are available. The point size indicates the number of documents with the corresponding combination. The red dots indicate the estimated height that is used when only gathering information is available. It seems that in most documents, the given height is smaller than the correponding estimate.

```{r summarysizevalidation, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
# Compare given dimensions to gatherings
# (not so much data with width so skip that)
df2 <- filter(df, !is.na(height) | !is.na(width))
df2 <- df2[!is.na(as.character(df2$gatherings)),]
df3 <- filter(df2, !is.na(height))
ss <- sheet_sizes()
df3$gathering.height.estimate <- ss[match(df3$gatherings, ss$gatherings),"height"]
df4 <- df3 %>% group_by(gatherings, height) %>% tally()
p <- ggplot(df4, aes(y = gatherings, x = height))
p <- p + geom_point(aes(size = n))
p <- p + geom_point(data = unique(df3), aes(y = gatherings, x = gathering.height.estimate), color = "red")
p <- p + ylab("Gatherings (original)") + xlab("Height (original)") 
p <- p + ggtitle("Height comparison")
print(p)
```

### Gatherings timelines

```{r papercompbyformat, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10, fig.height=7}
dfs <- df %>% filter(!gatherings == "NA" & publication_decade > 1450 & publication_decade < 2020)
res <- paper_timeline(dfs, "gatherings", nmin = 15) 
print(res$plot)
```

## Average page counts 

Multi-volume documents average page counts are given per volume.

```{r summarypagecountsmulti, echo=FALSE, message=FALSE, warning=FALSE}
mean.pagecounts.multivol <- mean_pagecounts_multivol(df) 
mean.pagecounts.univol <- mean_pagecounts_univol(df) 
mean.pagecounts.issue <- mean_pagecounts_issue(df) 
mean.pagecounts <- full_join(mean.pagecounts.univol, mean.pagecounts.multivol, by = "doc.dimension")
mean.pagecounts <- full_join(mean.pagecounts, mean.pagecounts.issue, by = "doc.dimension")
mean.pagecounts$doc.dimension <- factor(mean.pagecounts$doc.dimension, levels = levels(mean.pagecounts.univol$doc.dimension))
mean.pagecounts$doc.dimension <- order_gatherings(mean.pagecounts$doc.dimension)
kable(mean.pagecounts, caption = "Average page counts")
```


```{r summarypagecountsmulti2, echo=FALSE, message=FALSE, warning=FALSE, fig.width=15, fig.height=6}
p <- ggplot(melt(mean.pagecounts[, c("median.pages.multivol", "median.pages.singlevol", "median.pages.issue", "doc.dimension")]), aes(fill = variable, y = value, x = doc.dimension)) 
p <- p + geom_bar(stat = "identity", position = "dodge")
p <- p + ylab("Pages")
p <- p + xlab("")
p <- p + coord_flip()
p <- p + ggtitle("Median page counts")
p1 <- p

p <- ggplot(melt(mean.pagecounts[, c("mean.pages.multivol", "mean.pages.singlevol", "mean.pages.issue", "doc.dimension")]), aes(fill = variable, y = value, x = doc.dimension)) 
p <- p + geom_bar(stat = "identity", position = "dodge")
p <- p + ylab("Pages")
p <- p + xlab("")
p <- p + coord_flip()
p <- p + ggtitle("Mean page counts")
p2 <- p
grid.arrange(p1, p2, nrow = 1)
```


## Average document dimensions 

```{r summaryavedimstime, echo=FALSE, message=FALSE, warning=FALSE, fig.width=12, fig.height=7}
df2 <- filter(df, !is.na(gatherings) & (!is.na(height) | !is.na(width)) & publication_decade < 2020 & publication_decade > 1450) %>% group_by(gatherings, publication_decade) %>% 
  summarize(mean.height = mean(height, na.rm = T),
    	    mean.width = mean(width, na.rm = T), n = n())

p <- ggplot(df2, aes(x = publication_decade, y = mean.height, group = gatherings, color = gatherings))
p <- p + geom_point(aes(size = n))
p <- p + geom_smooth(method = "loess")
p <- p + ggtitle("Height")
print(p)
```


```{r summaryavedims, echo=FALSE, message=FALSE, warning=FALSE}
df2 <- filter(df, !is.na(gatherings) & (!is.na(height) | !is.na(width))) %>% group_by(gatherings) %>% 
  summarize(mean.height = mean(height, na.rm = T),
	    median.height = mean(height, na.rm = T),
    	    mean.width = mean(width, na.rm = T), 
	    median.width = mean(width, na.rm = T), 
	    n = n()) %>%
  filter(n > 10 & !is.na(as.character(gatherings)))
mean.dimensions <- as.data.frame(df2)
kable(mean.dimensions, caption = "Average document dimensions")
```

## Histograms of all entries for numeric variables

```{r summary-histograms, echo=FALSE, message=FALSE, warning=FALSE, fig.width=5, fig.height=4, fig.show='hold', out.width="200px"}
num <- c(); for (field in names(df)) {num[[field]] <- is.numeric(df[[field]])}
numeric.fields <- setdiff(names(which(num)), c("row.index", "original_row", "unity"))
for (field in numeric.fields) {
  df$fieldtoplot <- df[[field]]
  p <- ggplot(df, aes(x = fieldtoplot))
  p <- p + geom_histogram()
  #p <- p + scale_x_log10()
  p <- p + ggtitle(paste(field, "histogram"))
  p <- p + ylab("Documents")
  #p <- p + xlab(paste(field, "(log10)"))
  p <- p + xlab(field)  
  print(p)
}
```

## Histograms of the top entries for factor variables

```{r summary-bars, echo=FALSE, message=FALSE, warning=FALSE, fig.width=5, fig.height=4, fig.show='hold', out.width="200px"}
fac <- c(); for (field in names(df)) {fac[[field]] <- is.factor(df[[field]])}
factor.fields <- names(which(fac))
for (field in factor.fields) {
  #df$fieldtoplot <- df[[field]]
  n <- min(length(unique(df[[field]])), ntop)
  #p <- top_plot(df, "fieldtoplot", n)
  p <- top_plot(df, field, n)  
  p <- p + ggtitle(paste("Top ", field))
  p <- p + scale_y_log10()
  p <- p + ylab("Documents (Log10)")
  print(p)
}
```


